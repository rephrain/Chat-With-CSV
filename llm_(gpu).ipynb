{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "377d2ee356184e329c454ef239eeda17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5896991da88c4d23b82cf3ea43c911d2",
              "IPY_MODEL_07386b5ccfde49beae6ec6ebdec36cfb",
              "IPY_MODEL_b26aa4b986a142f493d9f5d931a9343f"
            ],
            "layout": "IPY_MODEL_81578175d3c741a4ba64d45e260c89ae"
          }
        },
        "5896991da88c4d23b82cf3ea43c911d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb5f33aecd0b426fb28bf633417c9339",
            "placeholder": "​",
            "style": "IPY_MODEL_df6d6d41e35947a894de4bd97f084b26",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "07386b5ccfde49beae6ec6ebdec36cfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d54bc746751f4b92ae665cb3a3d55c99",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fb19011aa9ea46e9ad9d88a951eef7fc",
            "value": 3
          }
        },
        "b26aa4b986a142f493d9f5d931a9343f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_638807e4e808461f829c045ded373727",
            "placeholder": "​",
            "style": "IPY_MODEL_78f82c1c6a4b45549335d8a605edd0e9",
            "value": " 3/3 [01:25&lt;00:00, 26.54s/it]"
          }
        },
        "81578175d3c741a4ba64d45e260c89ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb5f33aecd0b426fb28bf633417c9339": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df6d6d41e35947a894de4bd97f084b26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d54bc746751f4b92ae665cb3a3d55c99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb19011aa9ea46e9ad9d88a951eef7fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "638807e4e808461f829c045ded373727": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78f82c1c6a4b45549335d8a605edd0e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rephrain/Chat-With-CSV/blob/main/llm_(gpu).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers accelerate bitsandbytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnkVoJ85Jaug",
        "outputId": "d4968d8f-84fb-4052-8529-81308d58250a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.7.0)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.46.0-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.32.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Downloading bitsandbytes-0.46.0-py3-none-manylinux_2_24_x86_64.whl (67.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bitsandbytes\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed bitsandbytes-0.46.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yO5SKnKtFd5z",
        "outputId": "8874b95c-4566-4b0c-aa47-cb9954b7d8fb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.45.1-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.0)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.24.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.41.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.4.26)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.25.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.45.1-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.45.1 watchdog-6.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500,
          "referenced_widgets": [
            "377d2ee356184e329c454ef239eeda17",
            "5896991da88c4d23b82cf3ea43c911d2",
            "07386b5ccfde49beae6ec6ebdec36cfb",
            "b26aa4b986a142f493d9f5d931a9343f",
            "81578175d3c741a4ba64d45e260c89ae",
            "bb5f33aecd0b426fb28bf633417c9339",
            "df6d6d41e35947a894de4bd97f084b26",
            "d54bc746751f4b92ae665cb3a3d55c99",
            "fb19011aa9ea46e9ad9d88a951eef7fc",
            "638807e4e808461f829c045ded373727",
            "78f82c1c6a4b45549335d8a605edd0e9"
          ]
        },
        "id": "-7Bn7ImgHt9M",
        "outputId": "80092695-dbdc-4247-d461-7be1b4586469"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "377d2ee356184e329c454ef239eeda17"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-06-11 08:18:56.729 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-11 08:18:56.730 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-11 08:18:56.731 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-11 08:18:56.732 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-11 08:18:56.733 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-11 08:18:56.734 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-11 08:18:56.734 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-11 08:18:56.735 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-11 08:18:56.736 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-11 08:18:56.737 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-11 08:18:56.738 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-11 08:18:56.738 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-11 08:18:56.739 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-11 08:18:56.740 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-11 08:18:56.741 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-11 08:18:56.742 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-11 08:18:56.743 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-11 08:18:56.743 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-11 08:18:56.744 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-11 08:18:56.744 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-11 08:18:56.745 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-11 08:18:56.746 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-11 08:18:56.746 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-11 08:18:56.747 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-11 08:18:56.748 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-11 08:18:56.748 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ],
      "source": [
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io\n",
        "import json\n",
        "import re\n",
        "from typing import Dict, Any, List, Tuple, Optional, Union\n",
        "import sqlite3\n",
        "from datetime import datetime\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "import torch\n",
        "import warnings\n",
        "from dataclasses import dataclass\n",
        "from enum import Enum\n",
        "from datetime import datetime, timedelta\n",
        "import spacy\n",
        "from collections import defaultdict, Counter\n",
        "import json\n",
        "warnings.filterwarnings('ignore')\n",
        "import os\n",
        "torch.classes.__path__ = [os.path.join(torch.__path__[0], torch.classes.__file__)]\n",
        "\n",
        "class CSVProcessor:\n",
        "    \"\"\"Advanced CSV processing with data cleaning and analysis capabilities\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.df = None\n",
        "        self.metadata = {}\n",
        "        self.sql_connection = None\n",
        "\n",
        "    def load_and_process_csv(self, uploaded_file) -> pd.DataFrame:\n",
        "        \"\"\"Load CSV with robust processing and cleaning\"\"\"\n",
        "        try:\n",
        "            # Try different encodings\n",
        "            encodings = ['utf-8', 'latin-1', 'cp1252', 'iso-8859-1']\n",
        "\n",
        "            for encoding in encodings:\n",
        "                try:\n",
        "                    uploaded_file.seek(0)\n",
        "                    df = pd.read_csv(uploaded_file, encoding=encoding)\n",
        "                    break\n",
        "                except UnicodeDecodeError:\n",
        "                    continue\n",
        "            else:\n",
        "                raise ValueError(\"Could not decode file with any supported encoding\")\n",
        "\n",
        "            # Clean column names\n",
        "            df.columns = df.columns.str.strip().str.replace(r'[^\\w\\s]', '', regex=True)\n",
        "\n",
        "            # Advanced data type inference\n",
        "            df = self._infer_and_convert_types(df)\n",
        "\n",
        "            # Generate metadata\n",
        "            self._generate_metadata(df)\n",
        "\n",
        "            # Create SQL connection for complex queries\n",
        "            self._create_sql_connection(df)\n",
        "\n",
        "            self.df = df\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error processing CSV: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def _infer_and_convert_types(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"Advanced type inference and conversion\"\"\"\n",
        "        for col in df.columns:\n",
        "            # Skip if already numeric\n",
        "            if pd.api.types.is_numeric_dtype(df[col]):\n",
        "                continue\n",
        "\n",
        "            # Try to convert to numeric\n",
        "            numeric_series = pd.to_numeric(df[col], errors='coerce')\n",
        "            if not numeric_series.isna().all() and numeric_series.notna().sum() > len(df) * 0.5:\n",
        "                df[col] = numeric_series\n",
        "                continue\n",
        "\n",
        "            # Try to convert to datetime\n",
        "            try:\n",
        "                if df[col].dtype == 'object':\n",
        "                    datetime_series = pd.to_datetime(df[col], errors='coerce', infer_datetime_format=True)\n",
        "                    if datetime_series.notna().sum() > len(df) * 0.5:\n",
        "                        df[col] = datetime_series\n",
        "                        continue\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "            # Clean string columns\n",
        "            if df[col].dtype == 'object':\n",
        "                df[col] = df[col].astype(str).str.strip()\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _generate_metadata(self, df: pd.DataFrame):\n",
        "        \"\"\"Generate comprehensive metadata about the dataset\"\"\"\n",
        "        self.metadata = {\n",
        "            'shape': df.shape,\n",
        "            'columns': list(df.columns),\n",
        "            'dtypes': df.dtypes.to_dict(),\n",
        "            'numeric_columns': df.select_dtypes(include=[np.number]).columns.tolist(),\n",
        "            'categorical_columns': df.select_dtypes(include=['object']).columns.tolist(),\n",
        "            'datetime_columns': df.select_dtypes(include=['datetime64']).columns.tolist(),\n",
        "            'missing_values': df.isnull().sum().to_dict(),\n",
        "            'summary_stats': {}\n",
        "        }\n",
        "\n",
        "        # Generate summary statistics for numeric columns\n",
        "        for col in self.metadata['numeric_columns']:\n",
        "            self.metadata['summary_stats'][col] = {\n",
        "                'mean': float(df[col].mean()),\n",
        "                'median': float(df[col].median()),\n",
        "                'std': float(df[col].std()),\n",
        "                'min': float(df[col].min()),\n",
        "                'max': float(df[col].max()),\n",
        "                'count': int(df[col].count())\n",
        "            }\n",
        "\n",
        "    def _create_sql_connection(self, df: pd.DataFrame):\n",
        "        \"\"\"Create in-memory SQLite database for complex queries\"\"\"\n",
        "        self.sql_connection = sqlite3.connect(':memory:')\n",
        "        df.to_sql('data', self.sql_connection, index=False, if_exists='replace')\n",
        "\n",
        "    def execute_sql_query(self, query: str) -> pd.DataFrame:\n",
        "        \"\"\"Execute SQL query on the dataset\"\"\"\n",
        "        try:\n",
        "            return pd.read_sql_query(query, self.sql_connection)\n",
        "        except Exception as e:\n",
        "            st.error(f\"SQL Error: {str(e)}\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "class QueryType(Enum):\n",
        "    AGGREGATION = \"aggregation\"\n",
        "    FILTER = \"filter\"\n",
        "    COMPARISON = \"comparison\"\n",
        "    SUMMARY = \"summary\"\n",
        "    GROUPBY = \"groupby\"\n",
        "    CORRELATION = \"correlation\"\n",
        "    TEMPORAL = \"temporal\"\n",
        "    STATISTICAL = \"statistical\"\n",
        "    RANKING = \"ranking\"\n",
        "    COMPLEX_MULTI_STEP = \"complex_multi_step\"\n",
        "    PREDICTION = \"prediction\"\n",
        "    ANOMALY_DETECTION = \"anomaly_detection\"\n",
        "\n",
        "@dataclass\n",
        "class QueryContext:\n",
        "    \"\"\"Enhanced context for query processing\"\"\"\n",
        "    intent: QueryType\n",
        "    entities: List[Dict]\n",
        "    columns: List[str]\n",
        "    conditions: Dict[str, Any]\n",
        "    operations: List[str]\n",
        "    temporal_info: Dict[str, Any]\n",
        "    statistical_params: Dict[str, Any]\n",
        "    dependencies: List[str]\n",
        "    sub_queries: List[Dict]\n",
        "    visualization_hint: str\n",
        "\n",
        "class CSVProcessor:\n",
        "    \"\"\"Advanced CSV processing with data cleaning and analysis capabilities\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.df = None\n",
        "        self.metadata = {}\n",
        "        self.sql_connection = None\n",
        "\n",
        "    def load_and_process_csv(self, uploaded_file) -> pd.DataFrame:\n",
        "        \"\"\"Load CSV with robust processing and cleaning\"\"\"\n",
        "        try:\n",
        "            # Try different encodings\n",
        "            encodings = ['utf-8', 'latin-1', 'cp1252', 'iso-8859-1']\n",
        "\n",
        "            for encoding in encodings:\n",
        "                try:\n",
        "                    uploaded_file.seek(0)\n",
        "                    df = pd.read_csv(uploaded_file, encoding=encoding)\n",
        "                    break\n",
        "                except UnicodeDecodeError:\n",
        "                    continue\n",
        "            else:\n",
        "                raise ValueError(\"Could not decode file with any supported encoding\")\n",
        "\n",
        "            # Clean column names\n",
        "            df.columns = df.columns.str.strip().str.replace(r'[^\\w\\s]', '', regex=True)\n",
        "\n",
        "            # Advanced data type inference\n",
        "            df = self._infer_and_convert_types(df)\n",
        "\n",
        "            # Generate metadata\n",
        "            self._generate_metadata(df)\n",
        "\n",
        "            # Create SQL connection for complex queries\n",
        "            self._create_sql_connection(df)\n",
        "\n",
        "            self.df = df\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error processing CSV: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def _infer_and_convert_types(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"Advanced type inference and conversion\"\"\"\n",
        "        for col in df.columns:\n",
        "            # Skip if already numeric\n",
        "            if pd.api.types.is_numeric_dtype(df[col]):\n",
        "                continue\n",
        "\n",
        "            # Try to convert to numeric\n",
        "            numeric_series = pd.to_numeric(df[col], errors='coerce')\n",
        "            if not numeric_series.isna().all() and numeric_series.notna().sum() > len(df) * 0.5:\n",
        "                df[col] = numeric_series\n",
        "                continue\n",
        "\n",
        "            # Try to convert to datetime\n",
        "            try:\n",
        "                if df[col].dtype == 'object':\n",
        "                    datetime_series = pd.to_datetime(df[col], errors='coerce', infer_datetime_format=True)\n",
        "                    if datetime_series.notna().sum() > len(df) * 0.5:\n",
        "                        df[col] = datetime_series\n",
        "                        continue\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "            # Clean string columns\n",
        "            if df[col].dtype == 'object':\n",
        "                df[col] = df[col].astype(str).str.strip()\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _generate_metadata(self, df: pd.DataFrame):\n",
        "        \"\"\"Generate comprehensive metadata about the dataset\"\"\"\n",
        "        self.metadata = {\n",
        "            'shape': df.shape,\n",
        "            'columns': list(df.columns),\n",
        "            'dtypes': df.dtypes.to_dict(),\n",
        "            'numeric_columns': df.select_dtypes(include=[np.number]).columns.tolist(),\n",
        "            'categorical_columns': df.select_dtypes(include=['object']).columns.tolist(),\n",
        "            'datetime_columns': df.select_dtypes(include=['datetime64']).columns.tolist(),\n",
        "            'missing_values': df.isnull().sum().to_dict(),\n",
        "            'summary_stats': {}\n",
        "        }\n",
        "\n",
        "        # Generate summary statistics for numeric columns\n",
        "        for col in self.metadata['numeric_columns']:\n",
        "            self.metadata['summary_stats'][col] = {\n",
        "                'mean': float(df[col].mean()),\n",
        "                'median': float(df[col].median()),\n",
        "                'std': float(df[col].std()),\n",
        "                'min': float(df[col].min()),\n",
        "                'max': float(df[col].max()),\n",
        "                'count': int(df[col].count())\n",
        "            }\n",
        "\n",
        "    def _create_sql_connection(self, df: pd.DataFrame):\n",
        "        \"\"\"Create in-memory SQLite database for complex queries\"\"\"\n",
        "        self.sql_connection = sqlite3.connect(':memory:')\n",
        "        df.to_sql('data', self.sql_connection, index=False, if_exists='replace')\n",
        "\n",
        "    def execute_sql_query(self, query: str) -> pd.DataFrame:\n",
        "        \"\"\"Execute SQL query on the dataset\"\"\"\n",
        "        try:\n",
        "            return pd.read_sql_query(query, self.sql_connection)\n",
        "        except Exception as e:\n",
        "            st.error(f\"SQL Error: {str(e)}\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "class QueryType(Enum):\n",
        "    AGGREGATION = \"aggregation\"\n",
        "    FILTER = \"filter\"\n",
        "    COMPARISON = \"comparison\"\n",
        "    SUMMARY = \"summary\"\n",
        "    GROUPBY = \"groupby\"\n",
        "    CORRELATION = \"correlation\"\n",
        "    TEMPORAL = \"temporal\"\n",
        "    STATISTICAL = \"statistical\"\n",
        "    RANKING = \"ranking\"\n",
        "    COMPLEX_MULTI_STEP = \"complex_multi_step\"\n",
        "    PREDICTION = \"prediction\"\n",
        "    ANOMALY_DETECTION = \"anomaly_detection\"\n",
        "\n",
        "@dataclass\n",
        "class QueryContext:\n",
        "    \"\"\"Enhanced context for query processing\"\"\"\n",
        "    intent: QueryType\n",
        "    entities: List[Dict]\n",
        "    columns: List[str]\n",
        "    conditions: Dict[str, Any]\n",
        "    operations: List[str]\n",
        "    temporal_info: Dict[str, Any]\n",
        "    statistical_params: Dict[str, Any]\n",
        "    dependencies: List[str]\n",
        "    sub_queries: List[Dict]\n",
        "    visualization_hint: str\n",
        "\n",
        "class LLMQueryProcessor:\n",
        "    \"\"\"Enhanced LLM-based query processor with T5 text-to-SQL capabilities\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.tokenizer = None\n",
        "        self.model = None\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self._initialize_model()\n",
        "\n",
        "    def _initialize_model(self):\n",
        "        \"\"\"Initialize the SQLCoder model (Defog/sqlcoder-7b-2 with quantization)\"\"\"\n",
        "        try:\n",
        "            bnb_config = BitsAndBytesConfig(load_in_4bit=True)\n",
        "            model_name = \"defog/sqlcoder-7b-2\"\n",
        "\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "            self.model = AutoModelForCausalLM.from_pretrained(\n",
        "                model_name,\n",
        "                quantization_config=bnb_config,\n",
        "                device_map=\"auto\"\n",
        "            )\n",
        "            self.model.eval()\n",
        "\n",
        "        except Exception as e:\n",
        "            st.error(f\"Failed to load SQLCoder model: {str(e)}\")\n",
        "            st.warning(\"Falling back to rule-based SQL generation\")\n",
        "\n",
        "\n",
        "    def _clean_user_prompt(self, query: str) -> str:\n",
        "        \"\"\"Clean and preprocess user query\"\"\"\n",
        "        # Remove extra whitespace\n",
        "        query = re.sub(r'\\s+', ' ', query.strip())\n",
        "\n",
        "        # Remove special characters that might interfere with SQL generation\n",
        "        query = re.sub(r'[^\\w\\s\\-\\.\\,\\?\\!\\:\\;]', '', query)\n",
        "\n",
        "        # Convert to lowercase for better processing\n",
        "        query = query.lower()\n",
        "\n",
        "        # Remove common filler words that don't add value to SQL generation\n",
        "        filler_words = ['please', 'can you', 'could you', 'would you', 'i want to', 'i need to', 'help me']\n",
        "        for filler in filler_words:\n",
        "            query = query.replace(filler, '')\n",
        "\n",
        "        # Clean up extra spaces again\n",
        "        query = re.sub(r'\\s+', ' ', query.strip())\n",
        "\n",
        "        return query\n",
        "\n",
        "    def _generate_table_schema(self, metadata: Dict) -> str:\n",
        "        \"\"\"Generate SQL CREATE TABLE statement from metadata\"\"\"\n",
        "        columns = metadata.get('columns', [])\n",
        "        dtypes = metadata.get('dtypes', {})\n",
        "\n",
        "        # Map pandas dtypes to SQL types\n",
        "        type_mapping = {\n",
        "            'object': 'TEXT',\n",
        "            'int64': 'INTEGER',\n",
        "            'int32': 'INTEGER',\n",
        "            'float64': 'REAL',\n",
        "            'float32': 'REAL',\n",
        "            'bool': 'INTEGER',\n",
        "            'datetime64[ns]': 'TEXT',\n",
        "            'category': 'TEXT'\n",
        "        }\n",
        "\n",
        "        column_definitions = []\n",
        "        for col in columns:\n",
        "            dtype = str(dtypes.get(col, 'object'))\n",
        "            sql_type = type_mapping.get(dtype, 'TEXT')\n",
        "            # Clean column name for SQL compatibility\n",
        "            clean_col = re.sub(r'[^\\w]', '_', col)\n",
        "            column_definitions.append(f\"{clean_col} {sql_type}\")\n",
        "\n",
        "        schema = f\"CREATE TABLE data ({', '.join(column_definitions)})\"\n",
        "        return schema\n",
        "\n",
        "    def _generate_sql_with_sqlcoder(self, query: str, metadata: Dict) -> str:\n",
        "        \"\"\"Generate SQL using SQLCoder (Causal LM)\"\"\"\n",
        "        if not self.model or not self.tokenizer:\n",
        "            raise Exception(\"SQLCoder model not initialized\")\n",
        "\n",
        "        try:\n",
        "            # Generate the table schema from metadata\n",
        "            table_schema = self._generate_table_schema(metadata)\n",
        "\n",
        "            # Build the prompt format expected by SQLCoder\n",
        "            input_prompt = f\"\"\"\n",
        "    ### Task\n",
        "    Generate a SQL query to answer [QUESTION]{query}[/QUESTION]\n",
        "\n",
        "    ### Database Schema\n",
        "    The query will run on a database with the following schema:\n",
        "    {table_schema}\n",
        "\n",
        "    ### Answer\n",
        "    Given the database schema, here is the SQL query that [QUESTION]{query}[/QUESTION]\n",
        "    [SQL]\n",
        "    \"\"\".strip()\n",
        "\n",
        "            inputs = self.tokenizer(input_prompt, return_tensors=\"pt\").to(self.model.device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model.generate(\n",
        "                    **inputs,\n",
        "                    max_length=512,\n",
        "                    do_sample=False,\n",
        "                    temperature=0.7,\n",
        "                    top_p=0.95,\n",
        "                    num_return_sequences=1\n",
        "                )\n",
        "\n",
        "            generated_text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            generated_sql = generated_text.split(\"[SQL]\")[-1].strip()\n",
        "\n",
        "            # Optional: clean/validate the generated SQL\n",
        "            generated_sql = self._clean_generated_sql(generated_sql, metadata)\n",
        "\n",
        "            return generated_sql\n",
        "\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error generating SQL with SQLCoder: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def _clean_generated_sql(self, sql: str, metadata: Dict) -> str:\n",
        "        \"\"\"Clean and validate generated SQL query\"\"\"\n",
        "        # Remove any extra whitespace\n",
        "        sql = re.sub(r'\\s+', ' ', sql.strip())\n",
        "\n",
        "        # Ensure SQL ends with semicolon\n",
        "        if not sql.endswith(';'):\n",
        "            sql += ';'\n",
        "\n",
        "        # Replace table references to match our 'data' table\n",
        "        sql = re.sub(r'\\bFROM\\s+\\w+', 'FROM data', sql, flags=re.IGNORECASE)\n",
        "\n",
        "        # Clean column names to match our processed column names\n",
        "        columns = metadata.get('columns', [])\n",
        "        for col in columns:\n",
        "            clean_col = re.sub(r'[^\\w]', '_', col)\n",
        "            # Replace various possible column name formats\n",
        "            patterns = [\n",
        "                f'\\\\b{re.escape(col)}\\\\b',\n",
        "                f'\\\\b{re.escape(col.lower())}\\\\b',\n",
        "                f'\\\\b{re.escape(col.upper())}\\\\b'\n",
        "            ]\n",
        "            for pattern in patterns:\n",
        "                sql = re.sub(pattern, clean_col, sql, flags=re.IGNORECASE)\n",
        "\n",
        "        return sql\n",
        "\n",
        "    def parse_complex_query(self, query: str, metadata: Dict) -> QueryContext:\n",
        "        \"\"\"Parse and analyze complex queries\"\"\"\n",
        "        # Clean the user prompt\n",
        "        cleaned_query = self._clean_user_prompt(query)\n",
        "\n",
        "        # Simple intent classification\n",
        "        intent = self._classify_intent(cleaned_query)\n",
        "\n",
        "        # Extract relevant columns\n",
        "        columns = self._extract_columns(cleaned_query, metadata)\n",
        "\n",
        "        # Extract operations\n",
        "        operations = self._extract_operations(cleaned_query)\n",
        "\n",
        "        return QueryContext(\n",
        "            intent=intent,\n",
        "            entities=[],\n",
        "            columns=columns,\n",
        "            conditions={},\n",
        "            operations=operations,\n",
        "            temporal_info={},\n",
        "            statistical_params={},\n",
        "            dependencies=[],\n",
        "            sub_queries=[],\n",
        "            visualization_hint=\"\"\n",
        "        )\n",
        "\n",
        "    def _classify_intent(self, query: str) -> QueryType:\n",
        "        \"\"\"Classify the intent of the query\"\"\"\n",
        "        query_lower = query.lower()\n",
        "\n",
        "        if any(word in query_lower for word in ['average', 'mean', 'sum', 'count', 'max', 'min']):\n",
        "            return QueryType.AGGREGATION\n",
        "        elif any(word in query_lower for word in ['summary', 'describe', 'overview']):\n",
        "            return QueryType.SUMMARY\n",
        "        elif any(word in query_lower for word in ['group', 'by']):\n",
        "            return QueryType.GROUPBY\n",
        "        elif any(word in query_lower for word in ['where', 'filter', 'condition']):\n",
        "            return QueryType.FILTER\n",
        "        else:\n",
        "            return QueryType.AGGREGATION\n",
        "\n",
        "    def _extract_columns(self, query: str, metadata: Dict) -> List[str]:\n",
        "        \"\"\"Extract relevant columns from the query\"\"\"\n",
        "        columns = metadata.get('columns', [])\n",
        "        mentioned_columns = []\n",
        "\n",
        "        query_lower = query.lower()\n",
        "        for col in columns:\n",
        "            if col.lower() in query_lower:\n",
        "                mentioned_columns.append(col)\n",
        "\n",
        "        return mentioned_columns\n",
        "\n",
        "    def _extract_operations(self, query: str) -> List[str]:\n",
        "        \"\"\"Extract operations from the query\"\"\"\n",
        "        operations = []\n",
        "        query_lower = query.lower()\n",
        "\n",
        "        operation_keywords = {\n",
        "            'average': 'AVG',\n",
        "            'mean': 'AVG',\n",
        "            'sum': 'SUM',\n",
        "            'total': 'SUM',\n",
        "            'count': 'COUNT',\n",
        "            'maximum': 'MAX',\n",
        "            'max': 'MAX',\n",
        "            'minimum': 'MIN',\n",
        "            'min': 'MIN'\n",
        "        }\n",
        "\n",
        "        for keyword, operation in operation_keywords.items():\n",
        "            if keyword in query_lower:\n",
        "                operations.append(operation)\n",
        "\n",
        "        return operations\n",
        "\n",
        "    def generate_advanced_sql(self, context: QueryContext, metadata: Dict, query) -> Dict[str, Any]:\n",
        "        \"\"\"Generate advanced SQL based on context\"\"\"\n",
        "        try:\n",
        "            # Try to generate SQL using T5 model first\n",
        "            sql_query = self._generate_sql_with_t5(\n",
        "                query,\n",
        "                metadata\n",
        "            )\n",
        "\n",
        "            return {\n",
        "                'main_query': sql_query,\n",
        "                'context': context,\n",
        "                'success': True\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error generating SQL: {str(e)}\")\n",
        "\n",
        "            # Final fallback\n",
        "            fallback_query = self._fallback_sql_generation(\n",
        "                \" \".join(context.operations + context.columns),\n",
        "                metadata\n",
        "            )\n",
        "\n",
        "            return {\n",
        "                'main_query': fallback_query,\n",
        "                'context': context,\n",
        "                'success': False,\n",
        "                'error': str(e)\n",
        "            }\n",
        "\n",
        "class ChatCSVApp:\n",
        "    \"\"\"Main Streamlit application class\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.csv_processor = CSVProcessor()\n",
        "        self.llm_processor = LLMQueryProcessor()\n",
        "        # Initialize conversation history in session state\n",
        "        if 'conversation_history' not in st.session_state:\n",
        "            st.session_state.conversation_history = []\n",
        "\n",
        "    def run(self):\n",
        "        \"\"\"Main application runner\"\"\"\n",
        "        st.set_page_config(\n",
        "            page_title=\"Chat with CSV (LLM)\",\n",
        "            layout=\"wide\"\n",
        "        )\n",
        "\n",
        "        with st.container():\n",
        "            st.markdown(\n",
        "                \"\"\"\n",
        "                <div style='text-align: center;'>\n",
        "                    <h1>Chat with CSV (LLM)</h1>\n",
        "                    <p style='font-size: 18px;'>Upload a CSV file and ask questions in natural language to get intelligent insights!</p>\n",
        "                </div>\n",
        "                \"\"\",\n",
        "                unsafe_allow_html=True\n",
        "            )\n",
        "\n",
        "        # Sidebar for file upload and settings\n",
        "        with st.sidebar:\n",
        "            st.header(\"📁 File Upload\")\n",
        "            uploaded_file = st.file_uploader(\"Choose a CSV file\", type=\"csv\")\n",
        "\n",
        "            if uploaded_file is not None:\n",
        "                st.success(\"File uploaded successfully!\")\n",
        "\n",
        "                # Process the CSV\n",
        "                with st.spinner(\"Processing CSV...\"):\n",
        "                    df = self.csv_processor.load_and_process_csv(uploaded_file)\n",
        "\n",
        "        # Main content area\n",
        "        if uploaded_file is not None and self.csv_processor.df is not None:\n",
        "            col1, col2 = st.columns([1, 1])\n",
        "\n",
        "            with col1:\n",
        "                self._render_chat_interface()\n",
        "\n",
        "            with col2:\n",
        "                self._render_data_preview()\n",
        "        else:\n",
        "            st.info(\"Please upload a CSV file to get started!\")\n",
        "\n",
        "            # Show example queries\n",
        "            st.subheader(\"Example Queries\")\n",
        "            examples = [\n",
        "                \"What is the average age?\",\n",
        "                \"How many records are there?\",\n",
        "                \"Show me the maximum salary\",\n",
        "                \"What's the total revenue?\",\n",
        "                \"Give me a summary of the data\"\n",
        "            ]\n",
        "\n",
        "            for example in examples:\n",
        "                st.code(example)\n",
        "\n",
        "    def _render_chat_interface(self):\n",
        "        \"\"\"Render the chat interface\"\"\"\n",
        "        st.subheader(\"Chat Interface\")\n",
        "\n",
        "        # Display conversation history from session state FIRST\n",
        "        for i, (query, response_text, result_df, debug_info) in enumerate(st.session_state.conversation_history):\n",
        "            with st.chat_message(\"user\"):\n",
        "                st.markdown(query)\n",
        "            with st.chat_message(\"assistant\"):\n",
        "                st.markdown(response_text)\n",
        "\n",
        "                if result_df is not None:\n",
        "                    st.dataframe(result_df, use_container_width=True)\n",
        "\n",
        "                if debug_info:\n",
        "                    with st.expander(\"🧠 Debug Info\", expanded=False):\n",
        "                        for key, value in debug_info.items():\n",
        "                            if key == \"Generated SQL\":\n",
        "                                st.code(value, language=\"sql\")\n",
        "                            else:\n",
        "                                st.markdown(f\"- **{key}**: `{value}`\")\n",
        "\n",
        "            st.markdown(\"---\")\n",
        "\n",
        "        # Use a form for input - this auto-clears after submission\n",
        "        with st.form(key=\"query_form\", clear_on_submit=True):\n",
        "            query = st.text_input(\"Ask a question about your data:\",\n",
        "                                placeholder=\"e.g., What is the average age?\")\n",
        "            submitted = st.form_submit_button(\"Send\", type=\"primary\")\n",
        "\n",
        "        if submitted and query:\n",
        "            with st.spinner(\"Analyzing your query...\"):\n",
        "                response_text, result_df, debug_info = self._process_query(query)\n",
        "\n",
        "                # Save history for display\n",
        "                st.session_state.conversation_history.append((query, response_text, result_df, debug_info))\n",
        "                st.rerun()\n",
        "\n",
        "    def _process_query(self, query: str) -> Tuple[str, Optional[pd.DataFrame], dict]:\n",
        "        \"\"\"Returns (response_text, table_df, debug_info_dict)\"\"\"\n",
        "        try:\n",
        "            context = self.llm_processor.parse_complex_query(query, self.csv_processor.metadata)\n",
        "\n",
        "            # Collect debug info\n",
        "            debug_info = {\n",
        "                \"Query\": query,\n",
        "                \"Intent\": getattr(context, 'intent', 'N/A'),\n",
        "                \"Columns\": getattr(context, 'columns', []),\n",
        "                \"Operations\": getattr(context, 'operations', []),\n",
        "            }\n",
        "\n",
        "            sql_result = self.llm_processor.generate_advanced_sql(context, self.csv_processor.metadata, query)\n",
        "            sql_query = sql_result.get('main_query')\n",
        "            if sql_query:\n",
        "                debug_info[\"Generated SQL\"] = sql_query\n",
        "\n",
        "                result_df = self.csv_processor.execute_sql_query(sql_query)\n",
        "\n",
        "                if not result_df.empty:\n",
        "                    if len(result_df) == 1 and len(result_df.columns) == 1:\n",
        "                        value = result_df.iloc[0, 0]\n",
        "                        value_str = f\"**{value:.2f}**\" if isinstance(value, (int, float)) else f\"**{value}**\"\n",
        "                        return f\"The result is {value_str}\", None, debug_info\n",
        "                    else:\n",
        "                        return \"Here are the results:\", result_df, debug_info\n",
        "                else:\n",
        "                    return \"No results found for your query.\", None, debug_info\n",
        "\n",
        "            elif getattr(context, 'analysis_type', '') == 'summary':\n",
        "                return self._generate_summary_response(), None, debug_info\n",
        "\n",
        "            else:\n",
        "                return \"I need more specific information to give an accurate answer.\", None, debug_info\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"I encountered an error while processing your query:\\n\\n`{str(e)}`\", None, {}\n",
        "\n",
        "    def _generate_summary_response(self) -> str:\n",
        "        \"\"\"Generate a comprehensive summary of the dataset\"\"\"\n",
        "        metadata = self.csv_processor.metadata\n",
        "\n",
        "        summary = f\"\"\"\n",
        "**Dataset Summary:**\n",
        "\n",
        "**Basic Info:**\n",
        "- Total rows: {metadata['shape'][0]:,}\n",
        "- Total columns: {metadata['shape'][1]}\n",
        "\n",
        "**Column Types:**\n",
        "- Numeric columns: {len(metadata['numeric_columns'])}\n",
        "- Text columns: {len(metadata['categorical_columns'])}\n",
        "- Date columns: {len(metadata['datetime_columns'])}\n",
        "\n",
        "**Key Statistics:**\n",
        "\"\"\"\n",
        "\n",
        "        for col, stats in metadata['summary_stats'].items():\n",
        "            summary += f\"\\n**{col}:** Mean = {stats['mean']:.2f}, Range = {stats['min']:.2f} to {stats['max']:.2f}\"\n",
        "\n",
        "        return summary\n",
        "\n",
        "    def _render_data_preview(self):\n",
        "        \"\"\"Render comprehensive data preview and statistics\"\"\"\n",
        "        st.subheader(\"Data Preview\")\n",
        "\n",
        "        if self.csv_processor.df is not None:\n",
        "            df = self.csv_processor.df\n",
        "\n",
        "            # Create tabs for better organization\n",
        "            preview_tab, stats_tab, viz_tab, quality_tab = st.tabs([\n",
        "                \"Data Sample\", \"Statistics\", \"Visualizations\", \"Data Quality\"\n",
        "            ])\n",
        "\n",
        "            with preview_tab:\n",
        "                # Dataset overview\n",
        "                col1, col2, col3, col4 = st.columns(4)\n",
        "                with col1:\n",
        "                    st.metric(\"Total Rows\", f\"{len(df):,}\")\n",
        "                with col2:\n",
        "                    st.metric(\"Total Columns\", len(df.columns))\n",
        "                with col3:\n",
        "                    st.metric(\"Memory Usage\", f\"{df.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
        "                with col4:\n",
        "                    st.metric(\"Duplicate Rows\", df.duplicated().sum())\n",
        "\n",
        "                # Show customizable data sample\n",
        "                st.subheader(\"Data Sample\")\n",
        "                sample_size = st.slider(\"Number of rows to display:\", 5, min(50, len(df)), 10)\n",
        "                sample_type = st.radio(\"Sample type:\", [\"First rows\", \"Random sample\", \"Last rows\"], horizontal=True)\n",
        "\n",
        "                if sample_type == \"First rows\":\n",
        "                    sample_df = df.head(sample_size)\n",
        "                elif sample_type == \"Random sample\":\n",
        "                    sample_df = df.sample(min(sample_size, len(df))) if len(df) > 0 else df\n",
        "                else:\n",
        "                    sample_df = df.tail(sample_size)\n",
        "\n",
        "                st.dataframe(sample_df, use_container_width=True)\n",
        "\n",
        "                # Column information\n",
        "                st.subheader(\"Column Information\")\n",
        "                col_info = pd.DataFrame({\n",
        "                    'Column': df.columns,\n",
        "                    'Data Type': df.dtypes.astype(str),\n",
        "                    'Non-Null Count': df.count(),\n",
        "                    'Null Count': df.isnull().sum(),\n",
        "                    'Null %': (df.isnull().sum() / len(df) * 100).round(2),\n",
        "                    'Unique Values': df.nunique(),\n",
        "                    'Unique %': (df.nunique() / len(df) * 100).round(2)\n",
        "                })\n",
        "                st.dataframe(col_info, use_container_width=True)\n",
        "\n",
        "            with stats_tab:\n",
        "                numeric_cols = self.csv_processor.metadata['numeric_columns']\n",
        "                categorical_cols = [col for col in df.columns if col not in numeric_cols]\n",
        "\n",
        "                # Numeric statistics\n",
        "                if numeric_cols:\n",
        "                    st.subheader(\"Numeric Columns Statistics\")\n",
        "                    numeric_stats = df[numeric_cols].describe()\n",
        "                    st.dataframe(numeric_stats, use_container_width=True)\n",
        "\n",
        "                    # Additional statistics\n",
        "                    st.subheader(\"Additional Numeric Statistics\")\n",
        "                    additional_stats = pd.DataFrame({\n",
        "                        'Column': numeric_cols,\n",
        "                        'Skewness': [df[col].skew() for col in numeric_cols],\n",
        "                        'Kurtosis': [df[col].kurtosis() for col in numeric_cols],\n",
        "                        'Variance': [df[col].var() for col in numeric_cols],\n",
        "                        'Range': [df[col].max() - df[col].min() for col in numeric_cols],\n",
        "                        'IQR': [df[col].quantile(0.75) - df[col].quantile(0.25) for col in numeric_cols]\n",
        "                    })\n",
        "                    st.dataframe(additional_stats.round(3), use_container_width=True)\n",
        "\n",
        "                # Categorical statistics\n",
        "                if categorical_cols:\n",
        "                    st.subheader(\"Categorical Columns Statistics\")\n",
        "                    cat_stats = []\n",
        "                    for col in categorical_cols:\n",
        "                        if df[col].dtype == 'object' or df[col].dtype.name == 'category':\n",
        "                            mode_val = df[col].mode().iloc[0] if not df[col].mode().empty else 'N/A'\n",
        "                            cat_stats.append({\n",
        "                                'Column': col,\n",
        "                                'Unique Values': df[col].nunique(),\n",
        "                                'Most Frequent': mode_val,\n",
        "                                'Frequency': df[col].value_counts().iloc[0] if len(df[col].value_counts()) > 0 else 0,\n",
        "                                'Frequency %': (df[col].value_counts().iloc[0] / len(df) * 100).round(2) if len(df[col].value_counts()) > 0 else 0\n",
        "                            })\n",
        "\n",
        "                    if cat_stats:\n",
        "                        cat_df = pd.DataFrame(cat_stats)\n",
        "                        st.dataframe(cat_df, use_container_width=True)\n",
        "\n",
        "            with viz_tab:\n",
        "                st.subheader(\"Data Visualizations\")\n",
        "\n",
        "                # Visualization options\n",
        "                viz_type = st.selectbox(\"Choose visualization type:\", [\n",
        "                    \"Distribution Analysis\", \"Correlation Analysis\", \"Missing Data Pattern\", \"Category Analysis\"\n",
        "                ])\n",
        "\n",
        "                if viz_type == \"Distribution Analysis\" and numeric_cols:\n",
        "                    selected_col = st.selectbox(\"Select numeric column:\", numeric_cols)\n",
        "\n",
        "                    if selected_col:\n",
        "                        col1, col2 = st.columns(2)\n",
        "\n",
        "                        with col1:\n",
        "                            # Histogram\n",
        "                            fig_hist = px.histogram(df, x=selected_col,\n",
        "                                                title=f\"Distribution of {selected_col}\",\n",
        "                                                marginal=\"box\")\n",
        "                            st.plotly_chart(fig_hist, use_container_width=True)\n",
        "\n",
        "                        with col2:\n",
        "                            # Box plot\n",
        "                            fig_box = px.box(df, y=selected_col,\n",
        "                                            title=f\"Box Plot of {selected_col}\")\n",
        "                            st.plotly_chart(fig_box, use_container_width=True)\n",
        "\n",
        "                elif viz_type == \"Correlation Analysis\" and len(numeric_cols) > 1:\n",
        "                    # Correlation heatmap\n",
        "                    corr_matrix = df[numeric_cols].corr()\n",
        "                    fig_corr = px.imshow(corr_matrix,\n",
        "                                    title=\"Correlation Heatmap\",\n",
        "                                    color_continuous_scale=\"RdBu_r\",\n",
        "                                    aspect=\"auto\")\n",
        "                    fig_corr.update_layout(width=600, height=500)\n",
        "                    st.plotly_chart(fig_corr, use_container_width=True)\n",
        "\n",
        "                    # Pairwise scatter plot option\n",
        "                    if len(numeric_cols) >= 2:\n",
        "                        st.subheader(\"Pairwise Relationship\")\n",
        "                        col1, col2 = st.columns(2)\n",
        "                        with col1:\n",
        "                            x_col = st.selectbox(\"X-axis:\", numeric_cols, key=\"x_axis\")\n",
        "                        with col2:\n",
        "                            y_col = st.selectbox(\"Y-axis:\", [col for col in numeric_cols if col != x_col], key=\"y_axis\")\n",
        "\n",
        "                        if x_col and y_col:\n",
        "                            fig_scatter = px.scatter(df, x=x_col, y=y_col,\n",
        "                                                title=f\"{x_col} vs {y_col}\")\n",
        "                            st.plotly_chart(fig_scatter, use_container_width=True)\n",
        "\n",
        "                elif viz_type == \"Missing Data Pattern\":\n",
        "                    # Missing data visualization\n",
        "                    missing_data = df.isnull().sum()\n",
        "                    missing_data = missing_data[missing_data > 0].sort_values(ascending=False)\n",
        "\n",
        "                    if not missing_data.empty:\n",
        "                        fig_missing = px.bar(x=missing_data.values, y=missing_data.index,\n",
        "                                        orientation='h',\n",
        "                                        title=\"Missing Data by Column\",\n",
        "                                        labels={'x': 'Number of Missing Values', 'y': 'Columns'})\n",
        "                        st.plotly_chart(fig_missing, use_container_width=True)\n",
        "\n",
        "                        # Missing data percentage\n",
        "                        missing_pct = (missing_data / len(df) * 100).round(2)\n",
        "                        fig_pct = px.bar(x=missing_pct.values, y=missing_pct.index,\n",
        "                                    orientation='h',\n",
        "                                    title=\"Missing Data Percentage by Column\",\n",
        "                                    labels={'x': 'Percentage Missing', 'y': 'Columns'})\n",
        "                        st.plotly_chart(fig_pct, use_container_width=True)\n",
        "                    else:\n",
        "                        st.success(\"No missing data found in the dataset!\")\n",
        "\n",
        "                elif viz_type == \"Category Analysis\":\n",
        "                    categorical_cols_viz = [col for col in df.columns if df[col].dtype == 'object' or df[col].nunique() < 20]\n",
        "\n",
        "                    if categorical_cols_viz:\n",
        "                        selected_cat = st.selectbox(\"Select categorical column:\", categorical_cols_viz)\n",
        "\n",
        "                        if selected_cat:\n",
        "                            value_counts = df[selected_cat].value_counts().head(20)  # Top 20 categories\n",
        "\n",
        "                            col1, col2 = st.columns(2)\n",
        "                            with col1:\n",
        "                                # Bar chart\n",
        "                                fig_bar = px.bar(x=value_counts.index, y=value_counts.values,\n",
        "                                            title=f\"Distribution of {selected_cat}\")\n",
        "                                fig_bar.update_xaxes(tickangle=45)\n",
        "                                st.plotly_chart(fig_bar, use_container_width=True)\n",
        "\n",
        "                            with col2:\n",
        "                                # Pie chart (for top categories)\n",
        "                                top_categories = value_counts.head(10)\n",
        "                                fig_pie = px.pie(values=top_categories.values, names=top_categories.index,\n",
        "                                            title=f\"Top 10 Categories in {selected_cat}\")\n",
        "                                st.plotly_chart(fig_pie, use_container_width=True)\n",
        "                    else:\n",
        "                        st.info(\"No suitable categorical columns found for visualization.\")\n",
        "\n",
        "            with quality_tab:\n",
        "                st.subheader(\"Data Quality Assessment\")\n",
        "\n",
        "                # Overall data quality score\n",
        "                total_cells = len(df) * len(df.columns)\n",
        "                missing_cells = df.isnull().sum().sum()\n",
        "                duplicate_rows = df.duplicated().sum()\n",
        "\n",
        "                quality_score = max(0, 100 - (missing_cells / total_cells * 50) - (duplicate_rows / len(df) * 30))\n",
        "\n",
        "                st.metric(\"Data Quality Score\", f\"{quality_score:.1f}/100\")\n",
        "\n",
        "                # Quality issues breakdown\n",
        "                col1, col2 = st.columns(2)\n",
        "\n",
        "                with col1:\n",
        "                    st.subheader(\"Quality Issues\")\n",
        "                    issues = []\n",
        "\n",
        "                    if missing_cells > 0:\n",
        "                        issues.append(f\"• {missing_cells:,} missing values ({missing_cells/total_cells*100:.1f}% of all data)\")\n",
        "\n",
        "                    if duplicate_rows > 0:\n",
        "                        issues.append(f\"• {duplicate_rows:,} duplicate rows ({duplicate_rows/len(df)*100:.1f}% of total rows)\")\n",
        "\n",
        "                    # Check for potential outliers in numeric columns\n",
        "                    outlier_cols = []\n",
        "                    for col in numeric_cols:\n",
        "                        Q1 = df[col].quantile(0.25)\n",
        "                        Q3 = df[col].quantile(0.75)\n",
        "                        IQR = Q3 - Q1\n",
        "                        outliers = df[(df[col] < (Q1 - 1.5 * IQR)) | (df[col] > (Q3 + 1.5 * IQR))][col].count()\n",
        "                        if outliers > 0:\n",
        "                            outlier_cols.append(f\"{col}: {outliers} outliers\")\n",
        "\n",
        "                    if outlier_cols:\n",
        "                        issues.append(\"• Potential outliers detected:\")\n",
        "                        for outlier_info in outlier_cols:\n",
        "                            issues.append(f\"  - {outlier_info}\")\n",
        "\n",
        "                    if not issues:\n",
        "                        st.success(\"No major data quality issues detected!\")\n",
        "                    else:\n",
        "                        for issue in issues:\n",
        "                            st.warning(issue)\n",
        "\n",
        "                with col2:\n",
        "                    st.subheader(\"Recommendations\")\n",
        "                    recommendations = []\n",
        "\n",
        "                    if missing_cells > total_cells * 0.05:  # More than 5% missing\n",
        "                        recommendations.append(\"• Consider data imputation strategies for missing values\")\n",
        "\n",
        "                    if duplicate_rows > 0:\n",
        "                        recommendations.append(\"• Remove or investigate duplicate rows\")\n",
        "\n",
        "                    if len(outlier_cols) > 0:\n",
        "                        recommendations.append(\"• Investigate potential outliers in numeric columns\")\n",
        "\n",
        "                    # Check for high cardinality categorical columns\n",
        "                    high_card_cols = [col for col in df.columns if df[col].dtype == 'object' and df[col].nunique() > len(df) * 0.8]\n",
        "                    if high_card_cols:\n",
        "                        recommendations.append(f\"• Consider feature engineering for high-cardinality columns: {', '.join(high_card_cols)}\")\n",
        "\n",
        "                    if not recommendations:\n",
        "                        st.success(\"Data appears to be in good condition!\")\n",
        "                    else:\n",
        "                        for rec in recommendations:\n",
        "                            st.info(rec)\n",
        "\n",
        "                # Detailed column analysis\n",
        "                st.subheader(\"Detailed Column Analysis\")\n",
        "                problematic_cols = []\n",
        "\n",
        "                for col in df.columns:\n",
        "                    issues = []\n",
        "\n",
        "                    # Check missing values\n",
        "                    missing_pct = df[col].isnull().sum() / len(df) * 100\n",
        "                    if missing_pct > 20:\n",
        "                        issues.append(f\"High missing rate: {missing_pct:.1f}%\")\n",
        "\n",
        "                    # Check constant values\n",
        "                    if df[col].nunique() == 1:\n",
        "                        issues.append(\"Constant values (no variation)\")\n",
        "\n",
        "                    # Check high cardinality for categorical\n",
        "                    if df[col].dtype == 'object' and df[col].nunique() > len(df) * 0.9:\n",
        "                        issues.append(\"Very high cardinality\")\n",
        "\n",
        "                    if issues:\n",
        "                        problematic_cols.append({\n",
        "                            'Column': col,\n",
        "                            'Issues': ', '.join(issues),\n",
        "                            'Data Type': str(df[col].dtype),\n",
        "                            'Missing %': f\"{missing_pct:.1f}%\"\n",
        "                        })\n",
        "\n",
        "                if problematic_cols:\n",
        "                    prob_df = pd.DataFrame(problematic_cols)\n",
        "                    st.dataframe(prob_df, use_container_width=True)\n",
        "                else:\n",
        "                    st.success(\"All columns appear to be in good condition!\")\n",
        "\n",
        "        else:\n",
        "            st.warning(\"No data available. Please upload a CSV file first.\")\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function to run the Streamlit app\"\"\"\n",
        "    app = ChatCSVApp()\n",
        "    app.run()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run /usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LH3yY7IWF1_9",
        "outputId": "ee345a5c-ad07-4b0d-c213-5c9e5642f89b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.169.144.122:8501\u001b[0m\n",
            "\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}